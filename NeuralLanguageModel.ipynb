{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, GRU\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing the Text Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    # lower case text\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    # remove punctuations\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    long_words=[]\n",
    "    # remove short word\n",
    "    for i in newString.split():\n",
    "        if len(i)>=3:                  \n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once upon time land far far away there lived small but courageous cat named whiskers she would often spring and pounce chasing dappled shadows curious lights illuminating path towards hidden treasures her adventures she encounter dark creatures mystical spells and ally unexpected lightning fast and slow moving one step time whiskers would overcome each trial victorious and unyielding she return her cozy abode majestically purring with contentment\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\"Once upon a TIME, in a LAND far, FAR awayâ€”there LIVED a smAll but COURAGEOUS cat named WhiskerS! ShE would ofTen sPriNg and Pounce, chasing dappled shadows & curious LIGHTS: illuminating a PATH towards hidden TREASURES. In her AdVenturEs, she'd encounter dArK creatures, mystical SPELLS, and ALLY unexpected, LIGHTNING-FAST and slow-moving, one step at a time, WhiskerS wOuld OVERCOME each trial. Victorious and UNYIELDING, she'd return to her cozy abode, MAJESTICALLY PURRING with contentment 10/10\"\"\"\n",
    "\n",
    "# preprocess the text\n",
    "data_new = text_cleaner(data)\n",
    "print(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once the sequences are generated, the next step is to encode each character.\n",
    "\n",
    "**Encoding Sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n",
      "[[15], [14], [3], [5], [0], [20], [16], [15], [14], [0], [19], [9], [13], [5], [0], [12], [1], [14], [4], [0], [6], [1], [17], [0], [6], [1], [17], [0], [1], [22], [1], [24], [0], [19], [8], [5], [17], [5], [0], [12], [9], [21], [5], [4], [0], [18], [13], [1], [12], [12], [0], [2], [20], [19], [0], [3], [15], [20], [17], [1], [7], [5], [15], [20], [18], [0], [3], [1], [19], [0], [14], [1], [13], [5], [4], [0], [22], [8], [9], [18], [11], [5], [17], [18], [0], [18], [8], [5], [0], [22], [15], [20], [12], [4], [0], [15], [6], [19], [5], [14], [0], [18], [16], [17], [9], [14], [7], [0], [1], [14], [4], [0], [16], [15], [20], [14], [3], [5], [0], [3], [8], [1], [18], [9], [14], [7], [0], [4], [1], [16], [16], [12], [5], [4], [0], [18], [8], [1], [4], [15], [22], [18], [0], [3], [20], [17], [9], [15], [20], [18], [0], [12], [9], [7], [8], [19], [18], [0], [9], [12], [12], [20], [13], [9], [14], [1], [19], [9], [14], [7], [0], [16], [1], [19], [8], [0], [19], [15], [22], [1], [17], [4], [18], [0], [8], [9], [4], [4], [5], [14], [0], [19], [17], [5], [1], [18], [20], [17], [5], [18], [0], [8], [5], [17], [0], [1], [4], [21], [5], [14], [19], [20], [17], [5], [18], [0], [18], [8], [5], [0], [5], [14], [3], [15], [20], [14], [19], [5], [17], [0], [4], [1], [17], [11], [0], [3], [17], [5], [1], [19], [20], [17], [5], [18], [0], [13], [24], [18], [19], [9], [3], [1], [12], [0], [18], [16], [5], [12], [12], [18], [0], [1], [14], [4], [0], [1], [12], [12], [24], [0], [20], [14], [5], [23], [16], [5], [3], [19], [5], [4], [0], [12], [9], [7], [8], [19], [14], [9], [14], [7], [0], [6], [1], [18], [19], [0], [1], [14], [4], [0], [18], [12], [15], [22], [0], [13], [15], [21], [9], [14], [7], [0], [15], [14], [5], [0], [18], [19], [5], [16], [0], [19], [9], [13], [5], [0], [22], [8], [9], [18], [11], [5], [17], [18], [0], [22], [15], [20], [12], [4], [0], [15], [21], [5], [17], [3], [15], [13], [5], [0], [5], [1], [3], [8], [0], [19], [17], [9], [1], [12], [0], [21], [9], [3], [19], [15], [17], [9], [15], [20], [18], [0], [1], [14], [4], [0], [20], [14], [24], [9], [5], [12], [4], [9], [14], [7], [0], [18], [8], [5], [0], [17], [5], [19], [20], [17], [14], [0], [8], [5], [17], [0], [3], [15], [25], [24], [0], [1], [2], [15], [4], [5], [0], [13], [1], [10], [5], [18], [19], [9], [3], [1], [12], [12], [24], [0], [16], [20], [17], [17], [9], [14], [7], [0], [22], [9], [19], [8], [0], [3], [15], [14], [19], [5], [14], [19], [13], [5], [14], [19]]\n"
     ]
    }
   ],
   "source": [
    "# Create a character mapping index\n",
    "chars = sorted(list(set(data_new)))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "print(mapping)\n",
    "\n",
    "def encode_seq(seq):\n",
    "    sequences = list()\n",
    "    for line in seq:\n",
    "        # integer encode line\n",
    "        encoded_seq = [mapping[char] for char in line]\n",
    "        # store\n",
    "        sequences.append(encoded_seq)\n",
    "    return sequences\n",
    "\n",
    "# encode the sequences\n",
    "sequences = encode_seq(data_new)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model\n",
    "\n",
    "**We will use the embedding layer of Keras to learn a 50 dimension embedding for each character. This helps the model in understanding\n",
    "complex relationships between characters. We will also use a GRU layer as the base model, which has 150 time steps.\n",
    "Finally,  a dense layer with a Softmax activation for prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 50)            1300      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 150)               90900     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                3926      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96126 (375.49 KB)\n",
      "Trainable params: 96126 (375.49 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define vocabulary size\n",
    "vocab = len(chars)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab, 50, input_length=30, trainable=True))\n",
    "model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
    "model.add(Dense(vocab, activation='softmax'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # Fitting the model\n",
    "# model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once the model has finished training, we can generate text from the model given an input sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(n_chars):\n",
    "        # encode the characters as integers\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # one hot encode\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        # predict character\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # reverse map integer to character\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == yhat:\n",
    "                out_char = char\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += char\n",
    "    return in_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
