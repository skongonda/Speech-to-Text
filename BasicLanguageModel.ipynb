{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\skong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\skong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\skong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been successfully built!\n",
      "today the time they have been thinly traded on the unusual rise in manufacturing industries to win mandates , Morgan added .\n",
      "today the public sector debt fell by 5 . 25 European currency dealers said .\n",
      "today the company stressed in a 53 pct of Intercontinental Bank Holding Co , said it plans to join in when the Fed because it said .\n",
      "today the Turkish research ship which Greece had asked GATT to arbitrate on the commercial creditors would start within two to three billion stg level for the shareholder group consisting of 38 . 20 billion in 1985 .\n",
      "today the options reflect the merger called for stepped - up spending as highly unlikely that the substantial exchange rate trends , said Charles Stichler , an American army base near Athens as a huge rise in retail operating profit rose to 6 . 5p vs 5 , 545 , 160 short tons of low returns on commercial bills to a Senate Finance Committee ' s expenses and other market dependent influences just about weathered the worst recession in the Red Sea at 17 . 11 . 71 8 . 04 dlrs vs loss 24 , 311 , 000 dlrs\n"
     ]
    }
   ],
   "source": [
    "# Download the required datasets\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Initialize the model as a defaultdict of defaultdicts\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0.0))  # Using float for probabilities\n",
    "\n",
    "# Function to pad sentences manually\n",
    "def pad_sentence(sentence, n=3):\n",
    "    padding = [None] * (n - 1)\n",
    "    return padding + sentence + padding\n",
    "\n",
    "# Process sentences in the Reuters corpus\n",
    "for sentence in reuters.sents():\n",
    "    padded_sentence = pad_sentence(sentence)\n",
    "    for w1, w2, w3 in trigrams(padded_sentence):  # No pad_right, pad_left, or pad_symbol\n",
    "        model[(w1, w2)][w3] += 1\n",
    "\n",
    "# Convert counts to probabilities with smoothing\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] = (model[w1_w2][w3] + 1) / (total_count + len(model[w1_w2]))  # Laplace smoothing\n",
    "\n",
    "print(\"Model has been successfully built!\")\n",
    "\n",
    "# Function to generate random text\n",
    "def generate_text(starting_words, model, length=100):\n",
    "    text = starting_words[:]  # Create a copy to avoid modifying the original\n",
    "    sentence_finished = False\n",
    "    while not sentence_finished and len(text) < length:\n",
    "        next_word_candidates = model[tuple(text[-2:])]\n",
    "        if not next_word_candidates:\n",
    "            sentence_finished = True\n",
    "            break\n",
    "\n",
    "        # Use probabilities to pick the next word\n",
    "        words, probabilities = zip(*next_word_candidates.items())\n",
    "\n",
    "        # Normalize probabilities to ensure they sum to 1\n",
    "        probabilities = np.array(probabilities)\n",
    "        probabilities /= probabilities.sum()\n",
    "\n",
    "        try:\n",
    "            next_word = random.choices(words, probabilities)[0]\n",
    "        except IndexError:\n",
    "            sentence_finished = True\n",
    "            break\n",
    "\n",
    "        text.append(next_word)\n",
    "\n",
    "        if text[-2:] == [None, None] or len(model[tuple(text[-2:])]) == 0:\n",
    "            sentence_finished = True\n",
    "\n",
    "    return ' '.join([t for t in text if t])\n",
    "\n",
    "# Generate multiple random sentences\n",
    "starting_words = [\"today\", \"the\"]\n",
    "for _ in range(5):\n",
    "    generated_text = generate_text(starting_words, model)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
